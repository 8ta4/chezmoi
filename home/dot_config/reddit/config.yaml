https://www.reddit.com/r/socialmedia/comments/10z01nv/best_social_media_listening_tools/:
  text: |
    Best Social Media Listening Tools
    Professional Discussion
    I kinda feel like social media listening tools in the market are popping up in the market everyday & demand is also increasing. These are my favourite tools for social listening:

    1. Mention
    It‚Äôs one of the most used social listening tool as I always come across this tool in a conversation about social listening.

    Overall the tool is recommended by me because the resources & features they provide can help you better than other tools in the market.

    2. Brandwatch
    Brandwatch is a social media management tool, but they acquired Falcon, A social listening tool. Now, it‚Äôs the part of their platform and you can schedule & listen to your audience within their platform.

    One of the reasons I recommend them is they do great job at CX & collaborate well with HigherEd. If you work in HigherEd, I will recommend you to go for Brandwatch.

    3. Syften
    Syften can help you track conversations around your product & business on reddit, quora, hacker news & others.

    I don‚Äôt dislike the tool, but it‚Äôs best for SaaS owners, startups. It‚Äôs a scrappy social listening tool but it works. That‚Äôs why I mentioned it here.

    4. Brand 24
    Brand 24 is another great social listening tool with a better reporting process. You can track mentions across all main marketing channels & get reported.

    I myself came across brand24 recently through reddit suggestions. From what I have heard so far. It deserves to be here.

    5. Tweetdeck
    It‚Äôs the best tool to track conversations around your brand on Twitter.

    But some features like reporting & better CX isn‚Äôt the best part of Tweetdeck. As Twitter isn‚Äôt fully focused on users utilising this feature.

    But if your brand audience is active on twitter, this tool can deliver most accurate results.

    6. Gummy Search
    It‚Äôs one of the best tool to track conversations across reddit & you can also get analysis of sub-reddits where your target audience is active.

    Recommended to SaaS founders, startups & entrepreneurs to track conversations around their business.

    Honourable mentions
    Agorapulse & Sproutsocial are also famous for social listening but they are overall social media management tools. That‚Äôs why you might consider moving to them completely if your current tool lacks social listening features.

    Awario is a social listening tool with similar features to tools mentioned above but not a standout. That‚Äôs why it didn‚Äôt make the list.

    Google Alerts is one of my favourites but the tracking is limited to Google only.

    Thanks for reading. You can share your favourite social listening tool below & join r/marketingcurated for more tools & resource suggestions.
  threshold: 0.6253232955932618
https://www.reddit.com/r/mac/comments/13d9rfd/monitoring_plist_changes_and_generating/:
  text: |
    Monitoring plist changes and generating `PlistBuddy` commands
    Question
    I am looking for a tool or method to monitor plist changes on my Mac and generate the corresponding PlistBuddy commands when preferences are changed in macOS or apps. I want to avoid using defaults write since some preference values are nested. (Plists are like onions, they have layers upon layers, and just when you think you've peeled them all, another one appears to make you cry.)

    I've found these repositories, but they don't exactly do what I want:

    macos-defaults

    plistwatch

    My ideal workflow is as follows:

    Start the monitoring tool.

    Change preferences in macOS or apps.

    The tool shows PlistBuddy commands.

    Copy and paste the commands into my setup script.

    This would be similar to how Karabiner-EventViewer works for a different problem.

    Any suggestions on how to achieve this or existing tools that can help me with this workflow?
  threshold: 0.4066073000431062
https://www.reddit.com/r/selfhosted/comments/13tkasa/seeking_advice_on_developing_a_selfhosted_tool/:
  text: |
    Seeking advice on developing a self-hosted tool for monitoring and notifying users of relevant social media comments
    Hello r/selfhosted community,

    I'm about to embark on a journey of self-loathing, er, self-hosting, and I could use your advice. I'm working on a tool that monitors and notifies users of relevant social media comments related to a specific product using natural language processing and machine learning techniques. The draft of the documentation is available here.

    "Self-hosting? More like self-loathing because it's like being your own customer service representative, except the customer is an idiot, and that idiot is you." But I'm willing to take on the challenge because I want to ensure the tool is suitable for self-hosting and offers the flexibility and control that comes with it.

    Some of the challenges I'm facing include:

    Ensuring the tool can effectively monitor and analyze comments across various social media platforms.

    Handling potential false positives or negatives in the comment analysis.

    Designing an efficient notification system for users.

    I've recently posted a question on r/LanguageTechnology. However, that post is focused on NLP, and I'd like to shift the focus here to self-hosting aspects.

    I would appreciate any feedback, suggestions, or recommendations from the r/selfhosted community on the self-hosting aspects of this project. Are there any specific aspects you'd like to discuss or any additional features you think would be valuable for this tool?

    Thank you for your time and input!
  threshold: 0.6040834188461305
https://www.reddit.com/r/LanguageTechnology/comments/13sqmks/seeking_advice_on_developing_a_tool_to_monitor/:
  text: |
    Seeking Advice on Developing a Tool to Monitor and Notify Users of Relevant Social Media Comments
    I have been working on a tool that aims to monitor and notify users of relevant social media comments related to a specific product. I have documented my thoughts and ideas for this tool in this GitHub repository. The tool uses natural language processing and machine learning techniques to find and notify users of similar Reddit posts.

    I would like to ask for advice on the following aspects:

    Are there any existing tools or approaches that can help me with this task, or if there are any suggestions for how to effectively use NLP and machine learning techniques for this purpose?

    Any insights or resources related to NLP and machine learning in the context of social media monitoring would be greatly appreciated.

    They say NLP can predict our behavior. If only it could predict my next terrible joke, I'd save so much embarrassment.

    Please feel free to review the documentation and provide any feedback or suggestions. Thank you!
  threshold: 0.6342737078666688
https://www.reddit.com/r/chrome_extensions/comments/15074p2/how_do_you_install_configure_and_detect_changes/:
  text: |
    How do you install, configure, and detect changes in Chrome extensions programmatically?
    I'm working on a project that allows you to install, configure, and detect changes in Chrome extensions programmatically. I'm using Playwright and the chrome.* API for extension management.

    I'm looking for feedback. I even asked ChatGPT. It said, "Use your brain, you {headless: true}."

    I haven't started coding yet, but you can see my progress on GitHub.

    Here's how it works:

    To install an extension, it creates a preferences file and uses Playwright to enable the extension with the chrome.management.setEnabled method.

    To configure an extension, it uses Playwright to set the configuration values with the chrome.storage.sync.set method and other methods as needed.

    To detect changes in an extension, it uses Playwright to get the extension ID with the chrome.management.getAll method. Then, it uses Playwright to listen for changes with the chrome.storage.sync.addListener method and other methods as needed, generating JavaScript code based on the changes. Finally, it uses WebSocket to send the generated code to a logger.
  threshold: 0.6378690600395204
https://www.reddit.com/r/speechrecognition/comments/16b6kd4/247_speechtotext_transcription_tool_wanted/:
  text: |
    24/7 Speech-to-Text Transcription Tool Wanted
    I'm on the hunt for a tool that can record and transcribe my voice 24/7 to vocalize and capture every thought. For years, scientists worked tirelessly to give humans the gift of eternal memory. Now, every time I forget my anniversary, it's clearly on purpose.

    How I'll Use It
    Here are some ways I plan to use the transcriptions:

    Drafting Content: Mainly, I'll use it to draft messages, emails, social posts, documents - you name it!

    LLM Feedback: Another idea is to feed my daily thoughts into a Language Model (LLM) for insights and practical suggestions.

    Auto-Completion: In the long run, I'd love for the LLM to look at my past transcripts and auto-complete what I'm about to say.

    What I'm Looking For
    Here's what I need in this tool:

    Accuracy: It should catch every word I say, almost as good as a human would.

    Speed: It should be quick on its feet - ideally, less than a second's delay.

    Noise Resistance: A little background noise shouldn't throw it off.

    Budget: I'm hoping to keep it under $100/month. But hey, if it boosts my productivity, I might be willing to stretch that a bit.

    Storage: I'd love to keep the transcriptions forever, and the recordings too if it doesn't cost an arm and a leg. No need for the silent bits though. If it could sync up with Dropbox or something similar, that would be super convenient.

    Security: If it uses cloud storage, top-notch security measures like encryption are a must.

    Segmentation: It would be great if it could break up my transcript into manageable chunks. That way, if I switch topics mid-sentence, each topic gets its own segment.

    Integration: It would be awesome if it could work with macOS, Neovim, and Alacritty for drafting text. Something like a Neovim plugin or macOS clipboard integration would be really handy.

    Format: A simple text file with timestamps would do the trick. But hey, the more options, the merrier!

    Local Transcription: I'd prefer if it could transcribe locally, but I'm open to cloud-based solutions if they're more accurate or easier to maintain.

    Accessibility: I should be able to access the transcriptions from my computer. But my computer should not be the recording device.

    Hardware: Something stationary would work best. Maybe an old mobile phone or a Raspberry Pi. If there's wearable tech that can last all day and gives clearer recordings and more accurate transcriptions, I'm all for it!

    Voice Recognition: Ideally, it should only pick up my voice and ignore everyone else's. But if that's not possible, I can make sure no one else is around when I'm using it.

    Offline Use: An offline mode would be a nice bonus. But since I'll mostly be using this at home, it's not a deal-breaker.

    I know there are some privacy concerns with this kind of tool. But since it'll be in my home, I'm not too worried about invading anyone else's privacy.
  threshold: 0.6153409481048585
https://old.reddit.com/r/speechrecognition/comments/186bk2q/looking_for_the_ideal_microphone_for_247/:
  text: |
    Looking for the Ideal Microphone for 24/7 Transcription
    A couple of months ago, I embarked on a journey to find the perfect 24/7 speech-to-text transcription tool. It all started with a simple post on this subreddit. Now, I've got a question I'm hoping you can help with: What's the ideal microphone for this task? I'm all ears for feedback!

    The biggest hurdle has been finding the right microphone. I have two main requirements: it needs to be comfortable enough to wear all day and precise enough to isolate and transcribe my voice.

    u/Economics-Regular suggested an ear bone microphone, which sounds fascinating. But it seems that most ear bone mics are designed for military use, and they require a radio system to connect. I'm not sure if there is a consumer-friendly option that offers the same convenience as a standard headset, such as Bluetooth connectivity to a computer or phone.

    I've put more than a dozen microphones to the test, and the Poly Voyager 5200 came out on top. However, it's not without its flaws:

    Insufficient Noise Cancellation: It still picks up some background noise, especially loud announcements.
    Excessive Noise Cancellation: It sometimes cancels out my voice when I'm in a small enclosed space.
    Connectivity: There are occasional connectivity issues.
    Battery Life: It only lasts for 7 hours.
    Charging Port: It uses an old Micro USB instead of USB-C.
    Aside from the microphone hunt, I'm also exploring speaker verification. u/rdesh26 recommended the pre-trained ECAPA-TDNN model from SpeechBrain, which looks promising. However, this isn't a replacement for a high-quality microphone.

    I've also created a proof of concept. I have two branches:

    Main Branch: You can try this software, but it's very buggy.
    Develop Branch: This branch is my next rewrite and it's not working yet. Your feedback on this branch will help me improve this software.
    My hope is that by sharing this early-stage concept, it might spark collaborative improvements. Whether it's refining this tool or exploring a completely new approach, I'd love to team up if you're working on something similar or have insights to share.
  threshold: 0.6421288251876832
https://old.reddit.com/r/HeadphoneAdvice/comments/18pfkgu/looking_for_a_headset_that_can_handle_247/:
  text: |
    Looking for a Headset that Can Handle 24/7 Transcription: OpenComm 2, You're Almost There
    I've been working on a project to transcribe everything I say, all day, every day. You can check out the project goals.

    For that, I need the perfect headset: comfortable enough for all-day wear and capable of capturing my voice with crystal clear quality. You can see the headset requirements for more details.

    Do you know any good headsets that fit the bill?

    Just to give you an idea, I'm not shy about shelling out a grand if it's the right gear. At first, I spent a lot on a fancy Shure headset. My partner said, "I'm sure that was a sound investment." I said, "Sure, if only it could cancel all the noise you make!"

    Currently, I'm leaning toward Shokz's OpenComm 2. But it's not quite there yet. Here's why:

    Background Noise: Its mic struggles with background noise, especially loud announcements. The Poly Voyager 5200 did better. I tested them with some noise at arm's length. Voyager barely picked it up, but OpenComm 2 did.
    Voice Chat: Discord voice chat doesn't work at all.
    Multiple Device Connectivity: The ability to connect multiple devices and transmit audio signals simultaneously would be a game-changer. Sadly, OpenComm 2 doesn't support this.
    Reconnection: It doesn't automatically reconnect to my Mac when it comes back into range.
    Wind Noise: The Poly Voyager 5200's mic handles wind noise better. I tested them by holding them near an air conditioner. The Voyager didn't pick up much wind noise, but the OpenComm 2 did, sometimes as loud as my voice. I don't want to use a windscreen, because that's too much hassle.
    Muting: The mic doesn't auto-mute when I move the boom up.
    Comfort: It's mostly comfortable, but it starts to bother me after wearing it for a while.
    Charging: "The headset will automatically shut down when charging." This feature seems to be non-configurable.
    Charging Cable: I get the proprietary charging port for waterproofing, but using outdated USB-A instead of USB-C is a bummer.
    Audio Quality: I've noticed the sound starts to crackle even at medium volume.
    Playback Button: Ideally, double-clicking should skip to the next track, and triple-clicking should go back one. But this doesn't work with YouTube or Dropbox.
    Battery Display: The headset's battery level is visible when it's connected to my Mac via Bluetooth, but not when using a USB-C dongle. Plus, it's impossible to check my iPhone's battery level. Ideally, both my Mac and iPhone would display the headset's battery level consistently, just like they do for their batteries.
    So, I'm still looking for a better headset. Any leads would be appreciated!
  threshold: 0.704632043838502
https://old.reddit.com/r/slp/comments/193p53j/looking_for_a_tool_for_filler_word_analysis/:
  text: |
    Looking for a Tool for Filler Word Analysis
    I'm working on a personal project to improve my spoken language skills. I've created an open-source tool that transcribes everything I say 24/7. My transcript revealed that "uh" and "huh" are my most frequent fillers. It was an "uh-huh" moment!

    My goal now is to reduce the filler words I use.

    I thought of making another tool to count and analyze filler words.

    Does anyone know if there is something like this already, or a better way that experts in speech-language pathology would recommend? If it exists, I could just use it and save some time.

    Filler Word Analysis: The tool should tally up common filler words and provide their frequency.
    Baseline Comparison: It should compare my filler word usage with standard linguistic data (like Google's n-gram dataset) to determine if I'm above or below the norm.
    Sorting: The tool should rank filler words based on how much their frequency surpasses the baseline.
    Local Operation: The tool should operate locally to ensure privacy, as the transcripts are raw and unfiltered.
    User Interface: I like a command line interface that takes a text file as input and can also read from standard input. But hey, a graphical user interface could work too.
    Any suggestion is appreciated.
  threshold: 0.5055704116821290
https://old.reddit.com/r/QuantifiedSelf/comments/19a4zf3/looking_for_a_showerproof_noisecancelling_mic_for/:
  text: |
    Looking for a Shower-Proof, Noise-Cancelling Mic for 24/7 Life Transcription
    Is there a shower-friendly, noise-canceling microphone out there that can accurately capture my speech while I'm in the shower?

    I have this project where I want to transcribe everything I say, 24/7. I want to analyze my speech patterns, word choices, emotions, and more. I want to quantify myself through my voice.

    But there's a problem: I can't find a good microphone that can handle the shower.

    I've previously asked for advice on subreddits like r/HeadphoneAdvice (https://old.reddit.com/r/HeadphoneAdvice/comments/18pfkgu/looking_for_a_headset_that_can_handle_247/) and r/speechrecognition (https://old.reddit.com/r/speechrecognition/comments/186bk2q/looking_for_the_ideal_microphone_for_247/) before. Back then I was hunting for a noise-canceling mic for outdoor use. But no one seemed to care. Maybe they just didn't get it.

    But you guys get it. You're the quantified self community.

    I've tried a few devices, but none of them work well with water. Here's what I've tested so far:

    Bose SoundLink Micro Bluetooth Speaker: It picks up voice, but the moment you hit the shower, the transcription accuracy nosedives because it doesn't filter out the noise.
    OpenRun: The mic quality leaves a lot to be desired, especially when it's wet. It has an IP67 rating, but if you soak it in water, the sound quality drops and the transcription becomes gibberish.
    Voyager 5200: It's not waterproof, but I gave it a whirl in a mock shower setup (no direct water contact). The results were encouraging. It managed to separate my voice from the background noise well, hinting that the right waterproof mic could do the trick.
    I also gave Krisp, a noise-canceling software, a shot, hoping it would boost transcription accuracy. Here's the scoop:

    With the Bose and OpenRun, it didn't help because transcription was still useless.
    For the Voyager 5200, Krisp actually made the transcription worse.
    The real challenge is to find a mic that can: - Withstand the shower environment - Transcribe accurately even when it's wet or noisy.

    Then I had this brilliant idea: quit showering. It saves time and money. People leave me alone.

    But then I realized I can't stop showering because I got this genius idea in the shower.

    So, hit me with your recommendations and stories!
  threshold: 0.5880201458930970
https://old.reddit.com/r/macsysadmin/comments/1ant876/looking_for_a_free_adaptive_mac_ui_automation_tool/:
  text: |
    Looking for a Free, Adaptive Mac UI Automation Tool

    Do you know of any tool that can automate the ever-changing UI of a Mac app and doesn't cost a dime?

    I got this question when a user wanted to automate Apple Maps settings using plist. I thought it was a reasonable request since plist is supposed to track such changes. But I hit a roadblock when the setting they wanted to automate was nowhere to be found in plist files, so plist was useless.

    I was tempted to say, "Just use Google Maps." But I knew they'd say, "That's not the answer I need." It's a typical XY problem, so I skipped to Z: "Forget Maps. Just get lost."

    But then, it hit me. Maybe I'm the one stuck in the XY problem. I was limited by plist management. I wondered if I could try UI automation instead. Imagine being able to automate any setting, not just for Apple Maps but for any app, without relying on plist files or default commands.

    Take, for instance, changing the "Use Large Labels" setting in Apple Maps. A robust tool should be able to adapt to an additional step, a reorganized menu, or even a renamed setting. It should do this without any manual intervention.

    This is not just about tweaking settings. Generic AI-driven automation would let the user teach the AI how to do something, and then repeat it a hundred times.

    Here are my requirements:

    Adaptability: The tool should be able to handle software whose UI might change over time due to updates.
    Free: The tool should be free, maybe using a venture capital model where the initial user cost is subsidized, or running on my machine.
    Minimal Hardware Requirement: The tool should run on a recent base model Mac.
    I've considered some tools like Automator, AppleScript, Hammerspoon, SikuliX, Selenium, Puppeteer, and Playright. But they all have the same problem: they break when the UI changes.

    Are there any tools that meet these requirements?

    Someone suggested in the comments of my original post to seek advice here at r/MacSysAdmin. So, here I am!
  threshold: 0.4915493130683900
https://old.reddit.com/r/neovim/comments/1bn184l/looking_for_a_todo_app_that_works_with_neovim/:
  text: |
    Looking for a To-Do App that Works with Neovim

    Has anyone discovered a to-do app that seamlessly integrates Neovim text editing and offers comprehensive task management features?

    I wrote this question about finding the perfect to-do app months ago. The first task on my yet-to-be-discovered perfect app should have been, "Remember to post your question about finding the perfect to-do app."

    Here's what I'm looking for:

    A Mac app
    Neovim text editing
    Ergonomic keybinding for non-text editing tasks
    Local file storage for offline access
    Recurring tasks that auto-reschedule when marked done
    Due dates and start dates
    A keyboard-navigable calendar view
    Multi-line notes for each task
    Keyboard-only operation
    Low latency
    I've tried a few popular tools, but they just didn't cut it:

    Joplin: No Neovim keybinding
    Org-mode (Emacs): Too many keystrokes and occasional performance hiccups
    Org-mode (Neovim): Even more sluggish performance
    Taskwarrior: No multi-line notes and recurring tasks spawn new tasks
    Todo.txt: No ergonomic keybinding for non-text editing tasks
    Todoist: No Neovim keybinding and no local file storage
    I've also dabbled with embedding or integrating Neovim:

    Firenvim: Textarea doesn't expand as I type, so I have to scroll a lot. Sometimes it messes up the HTML elements. And it keeps the focus after editing, which breaks Vimium navigation.
    GhostText: It requires me to manually switch to Neovim every time I select a textarea.
    If you know of a tool that fits the bill or comes close, I'd love to hear about it! üôè
  threshold: 0.5506131649017335
https://old.reddit.com/r/AskProgramming/comments/1btmazw/looking_for_alternatives_to_deepgrams_whisper/:
  text: |
    Looking for Alternatives to Deepgram's Whisper Large for Transcription
    Are there any transcription APIs that can quickly transcribe audio recordings in multiple languages, without the reliability issues of Deepgram's Whisper Large model?

    Requirements: - Language Support: Strong in multiple languages at least on par with Deepgram's Whisper Large model. - Speed and Reliability: Looking to transcribe 60-second audio recordings within a second or slightly more. - Affordability: Competitively priced with Deepgram's $0.0048 per minute.

    Considered Options: - Self-Hosted Whisper: I want to avoid setting up something like Whisper by myself. - Deepgram's Whisper Large: The varying speeds of Deepgram's Whisper Large, sometimes taking over 10 seconds for just a few seconds of audio, are problematic. I'm developing this app to be an always-on transcription tool. But with these delays, it's more like it's always on a coffee break. - Deepgram's Nova-2 Model: I've been using Deepgram's Nova-2 model for transcribing English audio, and it's been great because of how fast and accurate it is. But now, I need something that can handle more languages.
  threshold: 0.4638389050960542
https://old.reddit.com/r/PromptEngineering/comments/1c3e85q/seeking_an_uncensored_capable_language_model_for/:
  text: |
    Seeking an Uncensored, Capable Language Model for Joke Generation
    Does anyone know of a language model that is uncensored but also has strong text-generation capabilities?

    I'm working on this project to automatically generate jokes using language models.

    The idea is to generate edgy punchlines, then for each punchline, generate a corresponding setup to misdirect the audience. After that, I'll filter out the duds by comparing the full jokes to a professional reference joke.

    Here's an example of the kind of joke I'm using as a reference, from comedian Jimmy Carr:

    Setup: "I would think about adoption. I don't have kids. But if I had kids,"

    Punchline: "I think I would have them adopted."

    My process looks like this:

    Come up with an edgy punchline related to a given topic (currently using Dolphin 2.6 Mixtral 8x7b)

    Create an innocent-sounding setup to misdirect the audience (using GPT-4 Turbo)

    Compare the complete joke to a professional reference joke to see how it stacks up (using GPT-3.5 Turbo)

    For more details on the goals of this project, check out my project documentation.

    Now, step number one is where I'm running into the most trouble. To generate a really edgy punchline, you need an uncensored model. And that's where most models fall short.

    Dolphin 2.6 Mixtral 8x7b is sweet because it's uncensored and can generate the kind of envelope-pushing humor I need for the punchlines. But in terms of raw language generation ability, it falls a bit short. The punchlines it generates often lack edge or coherence.

    If there are too many jokes to evaluate, it starts getting pricey. And the evaluation step isn't foolproof either - there could be some false positives that slip through. So I need to keep the number of punchlines reasonable.

    On the other hand, Claude Opus can generate some seriously high-quality text. But it's censored, even more than GPT-4. So it struggles with the darker topics that a lot of jokes revolve around.

    What I'm after is the best of both worlds - the no-holds-barred style of Dolphin Mixtral with the general capability of Claude Opus.

    If anyone has tips, I'm all ears!
  threshold: 0.4968124330043794
https://old.reddit.com/r/EnglishLearning/comments/1c8esz2/the_elusive_a_vs_the_need_a_tool_for_mastering/:
  text: |
    The Elusive "A" vs. "The": Need a Tool for Mastering Articles Based on Spoken Frequency
    Is there a resource that can help nail down articles and noun forms based on the most frequently spoken words?

    Let me tell you why I'm diving deep into articles and noun forms. While working on my always-on transcription tool, I noticed that speaking in standard English reduces errors in transcription. Plus, my tool's hooked up with Grammarly, which calls out my grammatical errors. It's through this integration that I've become more aware of the errors I make. So, I figure if I can nail down my article and noun usage, I'll improve my transcriptions. They say content words matter more than function words, but as a Grammar Nazi, I'll tell you: all words matter.

    If there's already a method that works, I want to use it. And even if a resource doesn't check all the boxes but does some things well, I'm down to see how it could fit into a bigger solution I might put together.

    Here's what I am looking for in a resource:

    Goal: To use the correct articles (definite, indefinite, or no article) and form of nouns (singular, plural) with 95% accuracy when speaking English.

    Approach: Cover 95% of the most frequently spoken nouns or noun meanings to achieve the goal.

    Data Source: Prefer spoken frequency data, but written frequency data can be used as a substitute if spoken data is not available.

    Data Format:

    Noun, sorted by spoken frequency.
    Test:
    Phrase or sentence with the article and noun hidden for a fill-in-the-blank style question.
    Keep determiners (like "some", "my", and "which") to a minimum in the test phrases, since they can mess with assessing if you understand countable and uncountable nouns. But determiners can be included if they're part of set expressions.
    Minimize the use of adverbs and adjectives unless part of set expressions.
    Short phrases are preferred over full sentences.
    Basic, commonly understood verbs and nouns that get the point across.
    Answer: The correct noun form and article to be filled in.
    Explanation:
    Identify the specific meaning of the noun used in the test.
    Outline the grammatical rule determining the correct article and noun form.
    Note if it is part of a set expression.
    Data Format Example:

    Noun: time
    Test: I lived in New York for ___.
    Answer: a time
    Explanation:
    "Time" in this context refers to a phase, making "time" singular.
    "For a time" is a set expression.
    Licensing: Open source or permissible for any purpose, including commercial use.

    There are tons of resources that talk about this stuff, but these resources don't cut it for me.

    'A' and 'The' Explained: It does a great job explaining the general principles of article usage, but it doesn't have that list of words covering 95% of spoken language.

    Oxford Advanced Learner's Dictionary:

    Fill-in-the-Blank: It's got examples, but not in that fill-in-the-blank style.
    Explanation: While it does tell you if a noun is countable or uncountable, it often lists multiple options without guidelines on when to use which one.
    Determiners: Examples often have determiners like "some".
    Modifiers: A lot of the examples are complex, with extra adjectives or adverbs.
    Licensing: Using their data is a gray area, even if it's for educational purposes.
  threshold: 0.4837861657142640
https://old.reddit.com/r/languagelearning/comments/1cd0b5c/seeking_a_pronunciation_grader_that_allows_any/:
  text: |
    Seeking a Pronunciation Grader That Allows Any Word, No Typing Required
    Do you know of a tool that can grade my pronunciation of any spoken word without needing to type?

    Here's the backstory: I developed a transcription tool that runs 24/7, and I've integrated it with Grammarly to highlight grammatical mistakes. But I've noticed that non-standard pronunciations often throw off the transcriptions. That's what got me thinking about ways to fix my pronunciation.

    I want to focus on how I pronounce individual words, avoiding complications like assimilation that happen in phrases or sentences.

    The dream scenario would be having a native speaker as a friend with benefits. If I nail it, she'll go, "Just like that!"

    But let's be real, having someone like that around 24/7 isn't realistic. So, I'm looking for a digital alternative.

    Here's what I'm looking for in this app:

    Web-Based: Requires no installation

    Accent Support: Lets me choose a specific accent, like Received Pronunciation, for the evaluation

    Word Flexibility: Lets me practice any word I want, not just a set list

    Multi-Word Feedback: Can evaluate an unlimited sequence of words, identifying where one word ends and the next begins, through pauses or keystrokes

    Low Latency: Evaluates my pronunciation with minimal latency like under a second after each word

    Scoring: Gives me a score of how close I am to the right pronunciation

    User Playback: Lets me listen to how I said the word

    Reference Playback: Lets me listen to a reference pronunciation to compare

    IPA Transcription: Shows the IPA symbols of how I pronounced the word

    Heteronym Support: Counts it right if I'm close to any of the acceptable ways to say it

    I've tried a couple of things so far, but they didn't quite do the trick:

    Elsa Speak: Makes me use a fixed lesson plan without letting me choose words

    Pronounce:

    Makes me type in words manually
    Can be buggy, especially with British English
    Doesn't give me a score of how close I am to the ideal pronunciation
    I'm using English as an example, but this could work for any language.

    If you have any suggestions, let me know!
  threshold: 0.5539534091949464
https://old.reddit.com/r/LanguageTechnology/comments/1cd8p3u/found_a_way_to_keep_transcripts_going_247/:
  text: |
    Found a Way to Keep Transcripts Going 24/7
    Last year, I hit up r/speechrecognition asking if anyone knew of a tool for continuous transcription. I didn't find anything that clicked, so I built one myself. It runs continuously in the background with nearly sub-second latency. I only noticed later that u/HaroldYardley had messaged me looking for the same thing. If one person's asking, more folks could use something like this. Since r/speechrecognition is a ghost town these days, I'm sharing this here.

    Here's what you can expect if you decide to try it out:

    It works exclusively on macOS with an Apple Silicon chip.
    Installation can be tricky.
    They say, "Create something to scratch your own itch." Well, I did and haven't stopped scratching since thanks to all the bugs.
    I don't check direct messages regularly, so if you have questions or feedback, feel free to post them here in this thread.
  threshold: 0.4662955403327943
https://old.reddit.com/r/AskTechnology/comments/1ckcu9b/looking_for_a_qa_site_that_only_uses_quotes_from/:
  text: |
    Looking for a Q&A Site That Only Uses Quotes from Famous People
    Do you know a site where you can ask questions and get answers only in the form of quotes from famous people?

    I don't like the existing sites because:

    Stack Exchange: Too factual, not enough opinions

    Quora: Too much self-promotion

    What I want is a site that has these features:

    Every answer is a direct quote from someone notable (people who have their own Wikipedia page)

    Every quote has a source (book title and page number, or article link with text highlight)

    Users can vote on answers

    If I post a question, "How do I pronounce Shia LaBeouf's last name?" the answer will be "Just Do It."

    Is there such a site out there?
  threshold: 0.36307042837142945
https://old.reddit.com/r/LanguageTechnology/comments/1cod8e1/can_llms_consistently_deliver_comedy/:
  text: |
    Can LLMs Consistently Deliver Comedy?
    How can I consistently create humor using Large Language Models (LLMs)?

    Here's where I'm at:

    Black Comedy: I started off trying to get LLMs to push the envelope with some edgy humor using an uncensored model.

    Unfortunately, they struggled to produce coherent text compared to censored models. This limitation led me to shelve this approach, which I talked about in a Reddit post.

    Wordplay: Next, I tried making jokes out of cliches and phrases. This method owes a lot to "Comedy Writing for Late-Night TV". My goal isn't to create the best jokes in the world but to churn out decent ones, kind of like what you'd hear on late-night TV daily. Here's a joke from Late Night with Jimmy Fallon that showcases the level of humor I'm aiming for: "An airline in Sweden plans to host the first-ever in-flight gay wedding in December. The entire flight crew is excited for the event, although the right wing isn't happy about it." You can dive deeper into my process in my guide.

    However, this approach can be hit or miss, and filtering out the duds is a chore.

    I'm thinking about automating the screening process of these jokes by funneling one prompt's output into another and managing the workflow with APIs.

    This could streamline things but also lock me into a rigid system. Plus, there's a risk of becoming obsolete quickly with new models or better joke-making techniques popping up.

    I'd value any alternative approaches or tweaks to my strategies. All suggestions are welcome!

    The content above was something I posted on r/Standup first, but it got taken down. I'm pretty sure it's because they didn't like the whole machine learning and comedy angle, which can be touchy for folks who do comedy the traditional way. So, I figured I'd bring it over here instead, where folks might dig into the tech side of things more and give me some solid feedback on how to make these machine-generated jokes sharper.
  threshold: 0.3990370035171510
https://old.reddit.com/r/AskProgramming/comments/1cxo5ch/seeking_speechtotext_api_recommendations/:
  text: |
    Seeking Speech-to-Text API Recommendations: Word-Level Probabilities, High Accuracy, Low Latency
    Are there any speech-to-text APIs that can give word-level probabilities, match or beat Deepgram in accuracy, and have low latency for short audio?

    About a month ago, I shared my experience with Deepgram on this subreddit, and the response was incredible. Recently, u/111ewe111 asked me what specific issues I was having with Deepgram. So, I thought I'd make this new post to answer those questions and the feedback I got since my needs have changed.

    Here's what I need from a speech-to-text API, in order of importance:

    Word-level probability: I need a probability for each word in the transcript.

    Accuracy: The API must be accurate, especially for common words in clear audio, finalizing the transcription only after the user finishes a sentence to make sure full context is considered.

    Latency: The API needs to be fast, ideally under 0.25 seconds per call for a single sentence.

    Cost: It should be affordable, aiming for under $1.215 per hour.

    Cross-origin resource sharing (CORS): This isn't a must-have, but it would be nice if the API supports CORS for direct use from the browser.

    Comparing speech-to-text API accuracy has been fruitful, like comparing apples to oranges, as many providers claim their solution is the best. This self-serving marketing makes it hard to determine the true accuracy of each API.

    I checked out a bunch of APIs that Deepgram mentioned in their blog post "Best Speech-to-Text APIs in 2024." Only the Nova-2 model from Deepgram and the Whisper API from OpenAI were able to return the API call within one second. But the Whisper API that OpenAI provides doesn't give you word-level probabilities. That's a dealbreaker.

    Deepgram claims to be the most accurate and fastest API, but I ran into two issues:

    Latency: Deepgram usually takes about 0.5 seconds to return a transcript for a single sentence. Most of this time is spent on TCP slow start, making the network the bottleneck.

    CORS: Deepgram doesn't support CORS, which is a bummer for browser-based apps.

    Most speech-to-text providers give you options like a streaming API and a prerecorded API. Take Deepgram, for example.

    With their streaming API, you get low latency because it processes the audio bit by bit as it comes in. But it might end up finalizing the transcription in the middle of a sentence. When that happens, the API loses the context for the rest of what's being said, which can sacrifice accuracy.

    Now, if you go with their prerecorded API, you'll probably get better accuracy since it looks at the full context of the audio. However, you're sending the whole audio file over, which can run into TCP slow start issues.

    There are a few potential solutions:

    A hybrid API that captures audio incrementally like streaming, but only finalizes transcriptions at the end of sentences.

    On-device transcription to eliminate network latency.

    To give you a bit more context, I'm designing an app that checks pronunciation. The goal is for the whole process to take less than a second. This involves three API calls: two for speech-to-text and one for text-to-speech. The text-to-speech call takes about 0.5 seconds, so each speech-to-text call needs to be around 0.25 seconds. I'm still figuring out if this is even possible. If you want to give me some feedback on the design, here's the link!

    All the latency numbers in this post were tested using Google Colab. It runs on Google's infrastructure, which helps minimize network latency. This way, I can be pretty sure that the network itself isn't the bottleneck during these tests.

    Now, let‚Äôs talk about cost. I have a budget of $100 per month, assuming 30 hours of usage each month. That gives me:

    $$\frac{\$100}{30 \text{ hours}} \approx \$3.33 \text{ per hour}$$

    I have three API calls: two for speech-to-text and one for text-to-speech. Let's estimate the number of characters processed in an hour. Assuming a fast speaker at 200 words per minute and 5 characters per word, I get:

    $$200 \text{ words/min} \times 60 \text{ min/hour} \times 5 \text{ characters/word} = 60,000 \text{ characters/hour}$$

    I'll use OpenAI's text-to-speech API, which costs $15 per million characters. The cost per hour for text-to-speech is:

    $$60,000 \text{ characters/hour} \times \frac{\$15}{1,000,000 \text{ characters}} = \$0.90 \text{ per hour}$$

    Next, I subtract the text-to-speech cost from my total hourly budget:

    $$\$3.33 - \$0.90 = \$2.43 \text{ per hour}$$

    This $2.43 covers my two speech-to-text API calls:

    $$\frac{\$2.43}{2} = \$1.215 \text{ per hour}$$

    Given all these requirements and challenges, I'm looking for recommendations for speech-to-text APIs.
  threshold: 0.4045410454273225
https://old.reddit.com/r/SaaS/comments/1cz4ek6/looking_for_a_service_to_automatically_publish/:
  text: |
    Looking for a Service to Automatically Publish Email Correspondence
    Is there a service that can automatically publish my emails with customer service, hiding all the personal info?

    Here's what I need:

    Automatic Redaction: It would automatically remove any sensitive stuff like account numbers and personal details.

    Public Publishing: It would publish the emails somewhere public, so other people could read them.

    Ease of Use: I could just CC a special email address when I'm emailing a company, and it would handle the rest.

    I think this could be useful for a couple of reasons:

    Knowledge Sharing: It would help people find answers to common problems, so they wouldn't have to keep bugging customer service about the same things.

    Better Customer Service: It might make companies step up their customer service game since they'd know their responses could end up public.

    Sharing is scaring.

    I recently had this thing happen with Hacker News. That's what got me wondering if there's a service that could handle this kind of thing.

    Here's the email:

    I am writing to seek assistance with an issue on Hacker News. It appears that my posts are not visible to other users, and this has happened on multiple occasions. This lack of visibility leads me to believe that my account may be shadow banned or that my posts are being flagged as spam.

    Could you please provide some guidance on why this might be happening?

    Here are the links to the posts in question: [REDACTED] [REDACTED]

    Your account's not banned, but HN's software is killing your posts because it thinks you're running afoul of the rule against using the site primarily for promotion‚Äîsee [REDACTED]: "Please don't use HN primarily for promotion. It's ok to submit your own stuff part of the time, but the primary use of the site should be for curiosity." Our software detects that sort of submission history and starts filtering the posts once the percentage of own-posts is too high.

    Below, I'll copy an explanation that we've sent to other users in this situation. I hope it helps explain things a bit!

    [REDACTED] (moderator)

    On HN, the idea is for people to submit stories that they ran across and personally found intellectually interesting, not because they have something to promote. It's fine to post your own work, as long as it's interspersed with interesting posts from unrelated sources. But when an account submits promotionally, it feels like they're not participating as a community member, and HN users notice this and flag the posts.

    It's best to build up a track record of interesting submissions from unrelated sources, and to intersperse your own articles with those. The software considers submission histories adaptively, so if you do that, your own-posts will eventually stop getting filtered.

    If you dig up interesting things from a variety of places, things people haven't run into before, then you'll be perceived as a community contributor rather than someone trying to market something. Particularly good are stories on out-of-the-way topics that rarely or never get attention. The best submissions are the ones that can't be predicted from any existing sequence.

    (Note: avoid posting major sites like youtube, twitter, medium, etc., for this purpose, because the software classifies them alongside the promotional posts so they won't help 'dig you out'. Ditto for Show HNs and Ask HNs (text posts) - avoid those until you're in the clear.)
  threshold: 0.4111687242984773
https://old.reddit.com/r/LanguageTechnology/comments/1cz6hk4/seeking_superior_texttospeech_api_alternatives_to/:
  text: |
    Seeking Superior Text-to-Speech API Alternatives to OpenAI
    Is there a TTS (Text-to-Speech) API out there that outshines OpenAI's TTS in terms of quality, latency, and cost?

    I have some specific criteria:

    Quality

    The most important aspect is how natural the generated speech sounds. For pronunciation practice, the naturalness of the speech is paramount.

    OpenAI's TTS has been excellent in this regard, providing clear and consistent word articulation.

    While Eleven Labs has speech that's full of emotion, it's pricier and isn't necessarily better for pronunciation practice.

    I don't rely on quality scores for TTS APIs; the proof is in putting the words together.

    Latency

    OpenAI's TTS API typically processes a sentence in about 0.5 seconds, which is decent. But there's room for improvement.

    Cost

    I want to keep my total monthly cost under $100.

    I prefer a pay-as-you-go model instead of a fixed-cost one with a usage cap.

    For my pronunciation practice, I'm looking at using it for up to 30 hours each month. I use Deepgram for speech-to-text, which runs me $0.0043 per minute and needs two API calls for each pronunciation. Here's a quick cost breakdown:

    Deepgram costs: 30 hours √ó 60 minutes/hour √ó 2 calls √ó $0.0043 per minute = $15.48

    Remaining budget for TTS: $100 - $15.48 = $84.52

    This project is all about instant feedback on pronunciation. You can check out the details to understand why these factors are crucial.

    So, if you know of a TTS API that beats OpenAI's in at least one of these areas while matching it in the others, hit me up!
  threshold: 0.40995657444000245
https://old.reddit.com/r/SideProject/comments/1d220ah/accent_precise_feedback_on_pronunciation_for/:
  text: |
    accent - Precise Feedback on Pronunciation for Every Word in Any Sentence
    Have you ever seen a tool that offers word-by-word precise feedback on your pronunciation for any sentence you want to practice?

    When it comes to learning pronunciation, speech recognition tech is the go-to for many. If it gets what you're saying, you're good to go. But it's a simple pass or fail.

    What I'm envisioning is a more detailed approach. Speech-to-text APIs often give word-level probabilities, showing how confident the system is in recognizing each word. A high probability means you nailed the pronunciation, while a low one suggests there's room for improvement. The idea is to use these probabilities to give more precise feedback.

    I've put together some documentation for the tool. But before I jump into development, I want to make sure I'm not reinventing the wheel. If you know of any tools that do this, please let me know! I'd really appreciate any feedback.

    Some people might think a tool like this could be perpetuating linguistic discrimination. I might be called an accentist or even worse, racist, for developing such an app. At least I'm not being hypocritical about it. TV presenters often preach about racism and diversity in the same perfect, standard accent. Accents speak louder than words!
  threshold: 0.48187774419784547
